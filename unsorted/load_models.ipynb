{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bd321b5-450f-41fd-b3d9-b5aa9c6cdf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10b45d45-8b41-41f0-b7b2-0d26f003cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "261128d6-489d-46df-858d-6f2ea304573e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e79efdc1-4be0-47bf-921b-303a07042845",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66679fec-1d9f-4e0e-8bcb-bae913170490",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_vox1_dev = \"/home/alexey/Documents/data/vox1_dev/wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb7655d-123f-4343-ab0a-06f1b8b62018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63de7885-3fa4-4bb8-bd5a-8a1b77bf3472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'voxceleb_trainer'...\n",
      "remote: Enumerating objects: 204, done.\u001b[K\n",
      "remote: Total 204 (delta 0), reused 0 (delta 0), pack-reused 204\u001b[K\n",
      "Receiving objects: 100% (204/204), 86.55 KiB | 895.00 KiB/s, done.\n",
      "Resolving deltas: 100% (114/114), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/clovaai/voxceleb_trainer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76b11bcd-59c5-4ecf-a9e6-e412cbde3b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p pretrained/clova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66f006b3-d273-4ad6-a5fa-1347c9f30fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-11-16 21:10:54--  http://www.robots.ox.ac.uk/~joon/data/baseline_v2_ap.model\n",
      "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
      "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://www.robots.ox.ac.uk/~joon/data/baseline_v2_ap.model [following]\n",
      "--2021-11-16 21:10:59--  https://www.robots.ox.ac.uk/~joon/data/baseline_v2_ap.model\n",
      "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 44573290 (43M)\n",
      "Saving to: ‘pretrained/clova/baseline_v2_ap.model’\n",
      "\n",
      "baseline_v2_ap.mode 100%[===================>]  42,51M   912KB/s    in 46s     \n",
      "\n",
      "2021-11-16 21:11:45 (943 KB/s) - ‘pretrained/clova/baseline_v2_ap.model’ saved [44573290/44573290]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.robots.ox.ac.uk/~joon/data/baseline_v2_ap.model -P pretrained/clova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4544a91-7118-42f6-8895-22f4bc4780b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a029385-f6d8-468f-b6a0-05356acee407",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"voxceleb_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18fe982a-50ec-478f-a73d-b579938b3d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model_clova(model_path, n_mels=64):\n",
    "\n",
    "    from voxceleb_trainer.models.ResNetSE34V2 import MainModel\n",
    "\n",
    "    clova_state = torch.load(model_path)\n",
    "    model = MainModel(nOut=512, encoder_type='ASP', n_mels=n_mels)\n",
    "    default_state = model.state_dict()\n",
    "\n",
    "    for name, param in clova_state.items():\n",
    "        if '__S__' in name:\n",
    "            valid_name = name[6:]\n",
    "            if valid_name not in default_state:\n",
    "                continue\n",
    "\n",
    "            if default_state[valid_name].size() != param.size():\n",
    "                print(f'mismatched size: model: {default_state[valid_name].size()}; state: {param.size()}')\n",
    "                continue\n",
    "\n",
    "            default_state[valid_name].copy_(param);\n",
    "\n",
    "    model.requires_grad_(False)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6df6a725-8091-443c-b94b-dfa311374f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'pretrained/clova/baseline_v2_ap.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec2dcc60-12b0-4538-8d7b-56d34e6580db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size is 512, encoder ASP.\n"
     ]
    }
   ],
   "source": [
    "emb_model = prepare_model_clova(model_path)\n",
    "emb_model = emb_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a332f32-5785-4088-87ff-aea695d37240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fc2b2d8-a9cb-40c6-bf5b-99409c3846a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(embedder, data_root, path2utt_fn=lambda p:p, batch_size=1, crop_size=None, crop_center=True, file_ext='wav', subset=None):\n",
    "    \n",
    "    embedder = embedder.eval()\n",
    "    \n",
    "    wav_files = glob2.glob(f'{data_root}/**/*.{file_ext}')\n",
    "    \n",
    "    if subset is not None:\n",
    "        wav_files = [wav for wav in wav_files if path2utt_fn(wav) in subset]\n",
    "        print('Subset:', len(subset))\n",
    "        print('Found:', len(wav_files))\n",
    "    \n",
    "    if crop_size is None:\n",
    "        assert batch_size == 1\n",
    "    crop_size_half = int(0.5 * crop_size)\n",
    "\n",
    "    embeddings = []\n",
    "    utt_ids = []\n",
    "\n",
    "    signals_batch = []\n",
    "    counter = 0\n",
    "    for i, wav_path in enumerate(tqdm(wav_files)):\n",
    "\n",
    "        utt_id = path2utt_fn(wav_path)\n",
    "        utt_ids += [utt_id]\n",
    "\n",
    "        signal, _ = torchaudio.load(wav_path)\n",
    "        length = signal.shape[-1]\n",
    "        length_half = int(0.5*length) \n",
    "        \n",
    "        if crop_size is not None:\n",
    "            if crop_center:\n",
    "                start = max(0, length_half - crop_size_half)\n",
    "                signal_crop = signal[..., start:start + crop_size] \n",
    "            else:\n",
    "                signal_crop = signal[..., :crop_size] \n",
    "                \n",
    "            # pad if signal is too short\n",
    "            if crop_size > length:\n",
    "                pad_size = (0, crop_size - length)\n",
    "                signal_crop = F.pad(signal_crop, pad_size)\n",
    "\n",
    "        signals_batch += [signal_crop]\n",
    "        counter += 1\n",
    "\n",
    "        if counter % batch_size == 0 or (i+1) == len(wav_files):\n",
    "            with torch.no_grad():\n",
    "                emb_batch = embedder(torch.cat(signals_batch).to(device)).cpu()\n",
    "\n",
    "            embeddings += [emb_batch]\n",
    "            signals_batch = []\n",
    "            counter = 0\n",
    "            \n",
    "    return embeddings, utt_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3a67bc-6070-4b6d-bacf-1e07dbd6ef4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "811b3870-84ee-4494-92ec-bba6d70474fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "crop_size = 16000\n",
    "crop_center = True\n",
    "\n",
    "path2utt_fn_vox = lambda wav_path: wav_path.split('/wav/')[-1]\n",
    "utt2spk_fn_vox = lambda utt: utt.split('/')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "032ff2f6-4126-4d9a-bcac-fba74bfc5023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148642/148642 [14:58<00:00, 165.49it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings, utt_ids = extract_embeddings(emb_model, \n",
    "                                         data_root_vox1_dev, \n",
    "                                         path2utt_fn_vox, \n",
    "                                         batch_size=batch_size, \n",
    "                                         crop_size=crop_size, \n",
    "                                         crop_center=crop_center)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90717089-6017-4c9b-8883-efd5603de1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.cat(embeddings).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ba29d77-835a-441f-99c8-b4e2f95349ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [utt2spk_fn_vox(utt) for utt in utt_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbf1c167-5219-455a-a8a5-933bb3a10326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148642, 148642, 148642)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings), len(utt_ids), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fb4d151-c12b-4f61-aa13-91aa3a77be89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.savez('./emb_vox1dev_clova_1sec', X=embeddings, ids=utt_ids, y=np.unique(labels, return_inverse=True)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5498cbe8-4eeb-4e79-9b1d-aea91d19a8a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc90770-8717-448c-9124-60e60e03e373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3dccf53-4cf1-4b2d-9a36-bbb8b8321192",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_asvspoof2019_train = \"/home/alexey/Documents/datasets/ASVspoof2019/PA/ASVspoof2019_PA_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d5916f76-58b9-4cfe-a9ce-d286065c84b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "crop_size = 16000\n",
    "crop_center = True\n",
    "file_ext = 'flac'\n",
    "\n",
    "path2utt_fn_asvspoof = lambda wav_path: wav_path.split('/')[-1].split('.')[0]\n",
    "utt2spk_fn_asvspoof = lambda utt: utt.split('/')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97907c45-944d-4ee1-abb2-e8c395e49c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../household/ASVspoof2019_train.txt', 'r') as f:\n",
    "    utt_ids = set([line.strip() for line in f.readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c5ae14f-d1b1-4bbc-92ff-db21565739e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5400"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(utt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8633649-9e64-4f9a-860c-351c5fd3bea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 100/5400 [00:00<00:05, 995.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset: 5400\n",
      "Found: 5400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5400/5400 [00:08<00:00, 623.80it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings, utt_ids = extract_embeddings(emb_model, \n",
    "                                         data_root_asvspoof2019_train, \n",
    "                                         path2utt_fn_asvspoof, \n",
    "                                         batch_size=batch_size, \n",
    "                                         crop_size=crop_size, \n",
    "                                         crop_center=crop_center,\n",
    "                                         file_ext=file_ext, \n",
    "                                         subset=utt_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b7bce34-1330-4929-93e1-28196d151a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.cat(embeddings).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "222d8650-4a7c-45a2-86e4-6b54ad0c4d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5400, 512)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc9f9fc6-9779-43eb-a476-8c5075982399",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = [utt2spk_fn_asvspoof(utt) for utt in utt_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "539436b0-57f9-478c-b744-74127e85e058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5400, 5400)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings), len(utt_ids)#, len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b75d900-553c-4b5c-bb68-c9872dd305c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.savez('./emb_asvspoof2019_train_clova_1sec', X=embeddings, ids=utt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762bfe8b-6638-49ee-aed1-6d2aa7bf4b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be5391e-9d8e-4895-89c0-7797076b99ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "007f3974-16c3-40ac-92f8-e5c562ea2d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_asvspoof2019_train = \"/home/alexey/Documents/datasets/ASVspoof2019/PA/ASVspoof2019_PA_eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cbc0dc29-8c77-499d-a8bf-42a17c7f7144",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "crop_size = 32000\n",
    "crop_center = True\n",
    "file_ext = 'flac'\n",
    "\n",
    "path2utt_fn_asvspoof = lambda wav_path: wav_path.split('/')[-1].split('.')[0]\n",
    "utt2spk_fn_asvspoof = lambda utt: utt.split('/')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "872d4196-7169-44a0-b37b-5e95953b02ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../household/ASVspoof2019_eval_test.txt', 'r') as f:\n",
    "    utt_ids = set([line.strip() for line in f.readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4bb05536-49be-4122-9b1c-10e9ba811e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129600"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(utt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0c3bfc77-6610-4565-87e5-438507520d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 94/129600 [00:00<02:18, 937.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset: 129600\n",
      "Found: 129600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129600/129600 [28:15<00:00, 76.45it/s] \n"
     ]
    }
   ],
   "source": [
    "embeddings, utt_ids = extract_embeddings(emb_model, \n",
    "                                         data_root_asvspoof2019_train, \n",
    "                                         path2utt_fn_asvspoof, \n",
    "                                         batch_size=batch_size, \n",
    "                                         crop_size=crop_size, \n",
    "                                         crop_center=crop_center,\n",
    "                                         file_ext=file_ext, \n",
    "                                         subset=utt_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c7c10374-cdad-4cf0-bca1-31f1ba81e67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.cat(embeddings).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "68dd5913-49dc-49b7-a0b7-b931eef4a930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129600, 512)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8360e369-db41-4f70-8120-202e696d3110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129600, 129600)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings), len(utt_ids)#, len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b5d595dd-a717-4c62-98f8-db160fd7954c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.savez('./emb_asvspoof2019_eval_test_clova_2sec', X=embeddings, ids=utt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da0c3c5-0c34-44d7-9cad-5531541f71f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8a652e-1ae0-4e08-9de7-ed6d8ef18cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "01424526-aa5c-467f-9e94-81ce33d86ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "crop_size = 16000\n",
    "crop_center = True\n",
    "file_ext = 'flac'\n",
    "\n",
    "path2utt_fn_asvspoof = lambda wav_path: wav_path.split('/')[-1].split('.')[0]\n",
    "utt2spk_fn_asvspoof = lambda utt: utt.split('/')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2214fa01-a03f-4436-a8cf-13fedff3f9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../household/ASVspoof2019_eval_test.txt', 'r') as f:\n",
    "    utt_ids = set([line.strip() for line in f.readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0d4be88b-18e9-423e-b100-a5a8af08ab54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129600"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(utt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4ca5a797-3358-4ae7-b267-e5499fe7f8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 87/129600 [00:00<02:29, 868.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset: 129600\n",
      "Found: 129600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129600/129600 [27:21<00:00, 78.97it/s] \n"
     ]
    }
   ],
   "source": [
    "embeddings, utt_ids = extract_embeddings(emb_model, \n",
    "                                         data_root_asvspoof2019_train, \n",
    "                                         path2utt_fn_asvspoof, \n",
    "                                         batch_size=batch_size, \n",
    "                                         crop_size=crop_size, \n",
    "                                         crop_center=crop_center,\n",
    "                                         file_ext=file_ext, \n",
    "                                         subset=utt_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b0901a26-34f6-41dd-90b3-eee53742ee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.cat(embeddings).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "76baecde-f72f-447f-95cf-fca5050418c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129600, 512)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5463e576-2dd7-43ed-b153-a7a0c40bbd5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129600, 129600)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings), len(utt_ids)#, len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cabe9bc3-c2d8-4261-9403-cea0d64aa600",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.savez('./emb_asvspoof2019_eval_test_clova_1sec', X=embeddings, ids=utt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4423e6b9-27f7-4532-ba00-bbab460ab418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e299e7b4-ed9d-4061-aec4-13905570854e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cba282a4-b326-4f61-b57e-8085d0c7c655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1211"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28e7742f-8128-485d-ba9f-4e30c5880253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115320 67476\n",
      "0.12526798 0.501915\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "\n",
    "def cosine(a, b):\n",
    "    a, b = torch.tensor(a), torch.tensor(b)\n",
    "    a_ln, b_ln = a / torch.norm(a, dim=1, keepdim=True), b / torch.norm(b, dim=1, keepdim=True)\n",
    "    return torch.mm(a_ln, b_ln.t()).numpy()\n",
    "\n",
    "similarity_score = cosine\n",
    "\n",
    "\n",
    "\n",
    "y = np.unique(labels, return_inverse=True)[1]\n",
    "\n",
    "sc_tar = []\n",
    "sc_imp = []\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(i, 5):\n",
    "        mask1 = y == i\n",
    "        x1 = embeddings[mask1]\n",
    "        mask2 = y == j\n",
    "        x2 = embeddings[mask2]\n",
    "        \n",
    "        if i == j:\n",
    "            #print(x1.shape, x2.shape)\n",
    "            sc_tar += [similarity_score(x1, x2).ravel()]\n",
    "        else:\n",
    "            #print(x1.shape, x2.shape)\n",
    "            sc_imp += [similarity_score(x1, x2).ravel()]\n",
    "            \n",
    "sc_tar = np.concatenate(sc_tar)\n",
    "sc_imp = np.concatenate(sc_imp)\n",
    "\n",
    "print(len(sc_imp), len(sc_tar))\n",
    "print(np.mean(sc_imp), np.mean(sc_tar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d015f1b-4bff-4129-9b3e-cdd87f4e4449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5851196670135276"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sc_tar)/len(sc_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd215223-59d9-4fe7-bf24-3c9b52ee0de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAANpklEQVR4nO3da4xcdRnH8d/PtgQNVcCuWgp10ShqjAiuaLylIkaoRDThhTcgBNMQo6mJN9Q39Z36whijiWmAgJFAjBKpBqJVWZFAwS0p2FrlZtRqY4t3faEWH1/MrC7L7M5/ds/lmTPfT7LpbOd08/w7c377P8/5nzOOCAEA8npK2wUAAJZHUANAcgQ1ACRHUANAcgQ1ACS3to4fumHDhpienq7jRwNAJ+3du/exiJga9FwtQT09Pa25ubk6fjQAdJLtXy31HK0PAEiOoAaA5AhqAEiOoAaA5AhqAEiOoAaA5AhqAEiOoAaA5AhqAEiOoAZGsGNH7wtoEkENAMkR1ACQHEENAMkR1ACQHEENAMkR1ACQHEENAMkR1ACQHEENAMkR1ACQHEENAMkR1ACQHEENAMkR1ACQHEENAMmtLd3Q9hpJc5J+GxEX1lfShJu/2TE3PU5t4cvDS4W6jTKj3i7pYF2FQOzxAAYqCmrbp0p6q6Sr6y0HALBYaevjC5I+Jmn9UhvY3iZpmyRt3rx51YUBbaO9gSyGBrXtCyUdiYi9trcstV1E7JS0U5JmZmaiqgInHj3rFPjvR5tKZtSvlfQ221slHS/p6ba/FhHvrbc0PAGB3Rj+i5HN0KCOiE9I+oQk9WfUHyGkG0BajA1+h6JurKMGgOSK11FLUkTMSpqtpRIAwEDMqMfVjh0cawMTgqAGgORGan0gAWbRaXFSEXUhqIGKcaEMqkbrAwCSI6gBIDlaH23iuBhAAWbUAJAcQQ0AyRHUAJAcPWpAnC5AbgQ1JhoBjXFA6wMAkmNG3QamcQBGwIwaAJIjqMcdtzsFOo+gBoDkCGqgRhzwoAoEdVeQCEBnEdQAkBzL84AG8GECWA1m1F1DCwToHIIaAJIjqAEgOXrUTaIlAWAFmFEDQHIENQAkR1ADQHIEdVexTA/oDIIaAJIjqAEgOYIaAJIjqAEgOYK66zihCIw9ghoAkuMS8iYwqwWwCsyogYaxxB2jYkaNicHN+zGuhs6obR9v+17b99s+YPvTTRSGCjGFA8ZayYz6n5LOjYi/214n6U7bt0XEnpprAwCoIKgjIiT9vf/tuv5X1FkUUDcOMDBOik4m2l5je5+kI5J2R8Q9A7bZZnvO9tzRo0crLhMAJldRUEfE4xHxckmnSjrH9ksHbLMzImYiYmZqaqriMlEJetXAWBpp1UdE/Nn2rKTzJe2vpaIuIRQBVKBk1ceU7RP7j58q6TxJP6+5LtSJmTUwVkpm1BslXW97jXrB/vWI+E69ZQEA5pWs+nhA0lkN1AJMlPmDGg5uMAyXkANAcgQ1ACRHUANAcgT1JGP1BzAWCGoASI6gBoDkCGoASI4PDgBaxgcaYBiCug7sbQAqRFCj88bp9yZXK2IQetQAkBxBDdZTA8kR1Pg/AhtIiaAGgOQIagBIjqDGk9ECAVIhqAEgOYIaAJLjghd0Ep0bdAkzagBIjqDG0jipCKRAUANAcgQ1ACTHyUQgIe5RjYWYUQNAcsyoq8TUBzXgHtVgRg0AyRHUGI5lekCraH1UgRADUCNm1ACQHEENAMkR1ChHiwdoBUENAMkR1MCYYPHN5CKoASA5luehU5hxoosIaoyG65lbxw2bJg+tDwBIbmhQ2z7N9u22D9o+YHt7E4UhOc5sAY0paX0ck/ThiLjP9npJe23vjoif1VwbAEAFM+qIOBwR9/Uf/03SQUmb6i4MANAzUo/a9rSksyTdM+C5bbbnbM8dPXq0ovIAAMVBbfsESd+U9KGI+Ovi5yNiZ0TMRMTM1NRUlTUCwEQrCmrb69QL6Rsi4uZ6SwIALFSy6sOSrpF0MCI+X39JGCus/gBqVzKjfq2kSySda3tf/2trzXWND0IKQM2GLs+LiDsluYFagBXj9yW6jCsTASA5ghoYY5wimAwENQAkx93zgA7gjnrdxowa1eAYHKgNQQ0AyRHUAJAcQQ0AyRHUAJAcqz5WihNng/GZikDlmFGjHqwCASpDUANAcgQ1ACRHjxpji84KJgUzagBIjqBGvTipCKwaQQ0AyRHUQMdwENM9BDUAJEdQA0ByBDUAJMc66lHR/FuZCu8BwkuAScOMGgCSI6jRLJYkNIb/6u6g9QF0HB98O/6YUQNAcgQ1ACRHUANAcgQ1ACRHUANAcqz6KMXpcgAtIagxFvg9iUlG6wMAkiOo0Q6myK3gasXxRFADQHIENQAkR1ADQHIENdpDwxQoMnR5nu1rJV0o6UhEvLT+kpIhSAC0rGRGfZ2k82uuA0CDOJgZL0ODOiLukPTHBmoBAAxQ2ZWJtrdJ2iZJmzdvrurHYsIx6wMqPJkYETsjYiYiZqampqr6sQAw8Vj1AQDJEdRoH2e2gGUNDWrbN0q6W9IZtg/ZvqL+sjCRCGxgoKEnEyPiXU0UAgAYjNYHAKxS3QeDfHAAMMEWhgtdp7wI6qXwrgWQBK0PAEiOoEY+rP4AnoDWB1KanZVmd7RdBZADQb0YMzlMqPm3PrtAPrQ+ACA5ghppbZndoS30PwBaH8hjdrbtCoCcmFEDQHIENQAkR1ADQHL0qOexJimt+ROKs1t2tFrHpOD+H/kwowaA5JhRo3Ws9gCWx4waAJIjqDE2uAAGk4rWB1pBuwMoR1BzWhtYEjdqyoHWBwAkR1Bj7NCrbh6f5dAughpji8DGpKBHDaAYVy22Y3KDmncZgDExuUGNVrAsDxgdPWqMPfrU7Zo/0chBan0mc0bNOwpYNXaj5kxmUKNxtDyAlaP1gU5gqR66jKAGUBl61fUgqNEpzKxzILCrRY8alaMfDVRrMoKaX+0Th89ZRJdMRlCjERln0gR2u7jkvBoENVYlYzgPQmC3j3tbr1y3g5p3RKUWhvKWLW1VsToEdvuYZY+um0HNq1+7cZlJL4XAzoFZdpmi5Xm2z7f9C9sP276q7qKQy+zs+AfzUljOlwPL+ZY3dEZte42kL0t6s6RDkn5ie1dE/Kzu4orxCteiq+E8yOKwZqbdDtoig5W0Ps6R9HBEPCpJtm+SdJGkZoN64a9cXsEnGBSo8z3kSQrbKi03yybEm7Hcbj5pEeCIWH4D+2JJ50fE+/rfXyLpVRHxgUXbbZO0rf/tGZJ+UVjDBkmPjVJ0Yowlry6Np0tjkbo1ntWM5bkRMTXoiZIZtQf83ZPSPSJ2Sto5YmGyPRcRM6P+u4wYS15dGk+XxiJ1azx1jaXkZOIhSact+P5USb+ruhAAwGAlQf0TSS+wfbrt4yS9U9KuessCAMwb2vqIiGO2PyDpu5LWSLo2Ig5UWMPI7ZLEGEteXRpPl8YidWs8tYxl6MlEAEC7uB81ACRHUANAco0Gte2Tbe+2/VD/z5MGbHOa7dttH7R9wPb2JmssMeySevd8sf/8A7bPbqPOEgVjeU9/DA/Yvsv2mW3UWaL0Vge2X2n78f41AmmVjMf2Ftv7+vvKj5qusVTB++wZtr9t+/7+WC5vo84Stq+1fcT2/iWer37/j4jGviR9TtJV/cdXSfrsgG02Sjq7/3i9pAclvaTJOoeMYY2kRyQ9T9Jxku5fXJ+krZJuU28N+qsl3dN23asYy2skndR/fME4j2XBdj+UdKuki9uue5WvzYnqXSG8uf/9s9quexVj+eR8HkiakvRHSce1XfsS43mDpLMl7V/i+cr3/6ZbHxdJur7/+HpJb1+8QUQcjoj7+o//JumgpE1NFVjgf5fUR8S/JM1fUr/QRZK+Gj17JJ1oe2PThRYYOpaIuCsi/tT/do966+gzKnldJOmDkr4p6UiTxa1AyXjeLenmiPi1JEVE1jGVjCUkrbdtSSeoF9THmi2zTETcoV59S6l8/286qJ8dEYelXiBLetZyG9uelnSWpHvqL63YJkm/WfD9IT35F0nJNhmMWucV6s0UMho6FtubJL1D0lcarGulSl6bF0o6yfas7b22L22sutGUjOVLkl6s3sV0P5W0PSL+00x5lat8/6/8ftS2vy/pOQOe+tSIP+cE9WY+H4qIv1ZRW0VKLqkvuuw+geI6bb9RvaB+Xa0VrVzJWL4g6eMR8Xhv4pZayXjWSnqFpDdJeqqku23viYgH6y5uRCVjeYukfZLOlfR8Sbtt/zjZvl+q8v2/8qCOiPOWes72721vjIjD/UOBgYdqttepF9I3RMTNVde4SiWX1I/LZfdFddp+maSrJV0QEX9oqLZRlYxlRtJN/ZDeIGmr7WMR8a1GKhxN6fvssYj4h6R/2L5D0pnqndfJpGQsl0v6TPSavA/b/qWkF0m6t5kSK1X5/t9062OXpMv6jy+TdMviDfo9qmskHYyIzzdYW6mSS+p3Sbq0f/b31ZL+Mt/ySWboWGxvlnSzpEsSztQWGjqWiDg9IqYjYlrSNyS9P2lIS2Xvs1skvd72WttPk/Qq9c7pZFMyll+rd2Qg289W7w6cjzZaZXWq3/8bPlv6TEk/kPRQ/8+T+39/iqRb+49fp95hwgPqHQrtk7S1yToLxrFVvVnLI5I+1f+7KyVd2X9s9T5s4RH1+m0zbde8irFcLelPC16LubZrXulYFm17nRKv+igdj6SPqrfyY796bcLW617h++wUSd/r7y/7Jb237ZqXGcuNkg5L+rd6s+cr6t7/uYQcAJLjykQASI6gBoDkCGoASI6gBoDkCGoASI6gBoDkCGoASO6/D2+BB2gbfQEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sc_tar, bins=100, density=True, alpha=0.5, color='b');\n",
    "plt.hist(sc_imp, bins=100, density=True, alpha=0.5, color='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a7bddf-58cf-44f9-bb02-f634e78680dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f03f2ae-8606-446f-a1f1-3c9c68bbf206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "722db410-c934-4f7d-a91c-c35dd5f4b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = 'pretrained/VBx/ResNet101_16kHz/nnet/final.onnx'\n",
    "backend = 'onnx'\n",
    "\n",
    "import onnxruntime\n",
    "\n",
    "def get_embedding(fea, model, label_name=None, input_name=None, backend='pytorch'):\n",
    "    if backend == 'pytorch':\n",
    "        data = torch.from_numpy(fea).to(device)\n",
    "        data = data[None, :, :]\n",
    "        data = torch.transpose(data, 1, 2)\n",
    "        spk_embeds = model(data)\n",
    "        return spk_embeds.data.cpu().numpy()[0]\n",
    "    elif backend == 'onnx':\n",
    "        return model.run([label_name],\n",
    "                  {input_name: fea.astype(np.float32).transpose()\n",
    "                  [np.newaxis, :, :]})[0].squeeze()\n",
    "\n",
    "if backend == 'pytorch':\n",
    "    raise NotImplementedError\n",
    "#     if args.model_file is not None:\n",
    "#         model = torch.load(args.model_file)\n",
    "#         model = model.to(device)\n",
    "#     elif args.model is not None and weights_path is not None:\n",
    "#         model = eval(args.model)(feat_dim=args.ndim, embed_dim=args.embed_dim)\n",
    "#         model = model.to(device)\n",
    "#         checkpoint = torch.load(weights_path, map_location=device)\n",
    "#         model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "#         model.eval()\n",
    "elif backend == 'onnx':\n",
    "    model = onnxruntime.InferenceSession(weights_path)\n",
    "    input_name = model.get_inputs()[0].name\n",
    "    label_name = model.get_outputs()[0].name\n",
    "\n",
    "else:\n",
    "    raise ValueError('Wrong combination of --model/--weights/--model_file '\n",
    "                     'parameters provided (or not provided at all)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed403ca2-eebc-46d5-891c-128bdca2b567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import features\n",
    "\n",
    "samplerate = 16000\n",
    "noverlap = 240\n",
    "winlen = 400\n",
    "window = features.povey_window(winlen)\n",
    "fbank_mx = features.mel_fbank_mx(winlen, samplerate, NUMCHANS=64, LOFREQ=20.0, HIFREQ=7600, htk_bug=False)\n",
    "\n",
    "fea = features.fbank_htk(signal.view(-1).numpy(), window, noverlap, fbank_mx, USEPOWER=True, ZMEANSOURCE=True)\n",
    "LC = 150\n",
    "RC = 149\n",
    "fea = features.cmvn_floating_kaldi(fea, LC, RC, norm_vars=False).astype(np.float32)\n",
    "\n",
    "xvector = get_embedding(fea, model, label_name=label_name, input_name=input_name, backend=backend)\n",
    "\n",
    "xvector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e366e5-fc80-441d-a196-c85889e08053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d470a9f7-f3e7-4827-842d-2f37e0be3431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e585116d-2fc9-4b66-a412-135e5010fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = torch.randn(1, 32000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ac6dc7c1-0b40-4f7f-bd19-8dd205a6e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from speechbrain.pretrained import EncoderClassifier\n",
    "classifier = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ed8225-16e7-421d-8d81-7d9ac4054644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1b1b671b-3e4c-4be1-b542-97c80992b5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = classifier.encode_batch(signal.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7797f8dc-02cf-4d47-8927-928723cfd415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 192])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7399bf18-ad30-47b9-8f91-29a322b6ae1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "79ffc393-47a0-401f-a767-9429972069a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speechbrain.pretrained.interfaces.EncoderClassifier"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EncoderClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cb9491f7-29fb-4e75-a422-42559eb441d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(378.5052)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d922eea2-af87-4064-a18f-f3480c21fe35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
